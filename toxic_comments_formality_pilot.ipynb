{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a58cb-5b9f-4fdc-b81d-21e59551fd35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39528cd5-1643-49f9-9702-52792f327947",
   "metadata": {},
   "source": [
    "# Are informal comments more toxic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bc5adb-a751-44f7-9fb4-6e45bb3b1adf",
   "metadata": {},
   "source": [
    "In this notebook we'll use Marianna Apidianaki's method of calculating interpretable dimensions in semantic vector space on the fly using seed pairs. To start, we want to look at the same dimensions: formality and complexity. But we want to look at the sentence level rather than the word level. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64cd02d-247b-4ed7-aece-9016a3ee1ddc",
   "metadata": {},
   "source": [
    "## Step 1: Generating formality seed pairs\n",
    "\n",
    "We want sevenish pairs of sentences, or really two symmetrical groups of sentences, that can be used to calculate a dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52b79f94-e41f-41e9-b776-0b10207066b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Last week I got into a car accident.',\n",
       " 'She had some amazing news to share but nobody to share it with.',\n",
       " 'Sometime you just have to give up and win by cheating.',\n",
       " 'They desperately needed another drummer since the current one only knew how to play bongos.',\n",
       " 'The bread dough reminded her of Santa Clause’s belly.',\n",
       " 'He realized there had been several deaths on this road, but his concern rose when he saw the exact number.',\n",
       " 'Trash covered the landscape like sprinkles do a birthday cake.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = \"\"\"Last week I got into a car accident.\n",
    "She had some amazing news to share but nobody to share it with.\n",
    "Sometime you just have to give up and win by cheating.\n",
    "They desperately needed another drummer since the current one only knew how to play bongos.\n",
    "The bread dough reminded her of Santa Clause’s belly.\n",
    "He realized there had been several deaths on this road, but his concern rose when he saw the exact number.\n",
    "Trash covered the landscape like sprinkles do a birthday cake.\"\"\"\n",
    "sentences = sentences.split(\"\\n\")\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe446b1-ef07-4030-9eeb-63a0ef9a4c41",
   "metadata": {},
   "source": [
    "### Step 1: Load and use GPT to generate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7a3886f-9fd0-4781-9a94-82542ac05227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI() # OPENAI_API_KEY environment variable must be set. see quickstart tutorial here: https://platform.openai.com/docs/quickstart?context=python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39baeeff-092f-4b8f-8fde-a95169a56564",
   "metadata": {},
   "source": [
    "Try an example completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7bef31c-7484-4c27-bdf0-bcf42db8c648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = sentences[0]\n",
    "\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a rewording assistant, skilled in transforming a statement to express more or less of a given quality or property.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Rephrase the following statement to use language that is more complex: \\\"{}\\\" .\".format(sentence)}\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6173d14c-9834-4e43-a916-b5baedbd7fce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='I experienced a vehicular collision the previous week.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d93ffd8-86c4-4953-a94c-7d9d5892a373",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='I experienced a vehicular collision the previous week.', role='assistant', function_call=None, tool_calls=None), logprobs=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d343e5f5-a508-4b9a-95c9-ad1315e46fae",
   "metadata": {},
   "source": [
    "We'll feed this output back to the api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d63610d-75c2-4125-aeab-f25cb52ef603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': 'You are a rewording assistant, skilled in transforming a statement to express more or less of a given quality or property.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Rephrase the following statement to use language that is more complex: \"Last week I got into a car accident.\" .'},\n",
       " {'role': 'system',\n",
       "  'content': 'I experienced a vehicular collision the previous week.'},\n",
       " {'role': 'user',\n",
       "  'content': 'Good. Rephrase the sentence again to use language that is even more complex.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.append({'role': 'system', 'content': completion.choices[0].message.content})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Good. Rephrase the sentence again to use language that is even more complex.\"})\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b443cea8-8f6d-4157-960a-fe70bdf18788",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'During the course of the preceding week, I found myself involved in a motor vehicle collision.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def complete(messages):\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=messages,\n",
    "      seed=42\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "complete(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e271c-6d51-4466-af8e-cad5e1d08146",
   "metadata": {},
   "source": [
    "### prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "443760eb-6c3e-4f17-a195-f79d0c18f0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dictionary of the adjectives we use (property adjective and antonym) to create prompts\n",
    "\n",
    "property_dict = {\n",
    "    'complexity':   ('complex', 'simple'),\n",
    "    'emotion':      ('emotional', 'emotionless')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a278d-99de-4e3d-a33a-3ce3df86e8ff",
   "metadata": {},
   "source": [
    "We will generate sentences from a series of templates. For each sentence, we want to generate 'more x', 'even more x', as well as 'less x' and 'even less x'. Because the model often produces longer sentences for 'more' prompts, we also prompt for rephrasings using an antonymous adjective. So, for example, we ask for rephrasings that are \"more complex\" as well as rephrasings that are \"less simple\". We then use all of these rephrasings to calculate the complexity dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf12b685-beec-476c-b2e6-b51a4d1ef21f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "complex\n",
      "The previous week, I was involved in a vehicular collision.\n",
      "During the preceding week, I found myself embroiled in a motor vehicle collision.\n",
      "I had a car accident last week.\n",
      "I had a crash with my car last week.\n",
      "1\n",
      "simple\n",
      "Last week, I was in a car crash.\n",
      "Last week, my car crashed.\n",
      "Last week I was involved in a collision while operating a motor vehicle.\n",
      "During the course of the previous week, I was engaged in a vehicular collision resulting in damage to my automobile.\n",
      "0\n",
      "complex\n",
      "She was in possession of astounding news, yet there was a dearth of individuals with whom she could disseminate it.\n",
      "She found herself in the possession of awe-inspiring tidings that yearned to be shared, however, she was met with the unfortunate circumstance of not having anyone in her proximity with whom she could partake in the act of disseminating the aforementioned news.\n",
      "She had incredible news to tell, but no one to tell it to.\n",
      "She had really great news, but no one to tell it to.\n",
      "1\n",
      "simple\n",
      "She had some great news to tell but no one to tell it to.\n",
      "She had really good news, but no one to tell it to.\n",
      "She possessed extraordinary tidings to impart, yet there was a dearth of individuals to whom she could divulge it.\n",
      "She harbored astonishing revelations to disseminate; however, a conspicuous absence of suitable confidants impeded their transmission.\n",
      "0\n",
      "complex\n",
      "Occasionally, one must relinquish and emerge victorious through resorting to dishonest tactics.\n",
      "On certain occasions, it becomes necessary to acquiesce and achieve success through the employment of deceitful methods.\n",
      "Sometimes you have no choice but to resort to cheating in order to win.\n",
      "Sometimes, cheating is the only way to win.\n",
      "1\n",
      "simple\n",
      "Sometimes you just have to cheat to win.\n",
      "Sometimes you have to cheat to win.\n",
      "Occasionally, one must relinquish and achieve victory through dishonest means.\n",
      "On certain occasions, it becomes necessary to concede and attain triumph through the utilization of deceitful tactics.\n",
      "0\n",
      "complex\n",
      "Due to an urgent requirement, an additional percussionist was decidedly crucial, given that the current incumbent's competencies were limited to bongo proficiency alone.\n",
      "In light of their acute predicament, it became abundantly clear that the acquisition of an additional percussionist was an utmost necessity, owing to the fact that the current incumbent possessed solely a rudimentary expertise limited exclusively to the realm of bongo playing.\n",
      "They really needed a new drummer because the current one could only play bongos.\n",
      "They really needed a new drummer because the current one could only play bongos.\n",
      "1\n",
      "simple\n",
      "They really needed a new drummer because the current one could only play bongos.\n",
      "They really needed a new drummer because the current one could only play bongos.\n",
      "They were in dire need of an additional percussionist as the current one possessed proficiency solely in bongo playing.\n",
      "They were in dire straits, desperately requiring the services of another percussionist, as their current one held expertise solely in the realm of bongo instrumentation.\n",
      "0\n",
      "complex\n",
      "The dough of the bread invoked in her mind the image of Santa Claus's rotund midsection.\n",
      "The visage of Santa Claus's ample abdomen was conjured within her thoughts upon encountering the dough that comprised the bread.\n",
      "The dough reminded her of Santa's belly.\n",
      "The dough reminded her of Santa's tummy.\n",
      "1\n",
      "simple\n",
      "The dough reminded her of Santa's belly.\n",
      "The dough reminded her of Santa's tummy.\n",
      "The dough of the bread invoked in her mind the image of Santa Claus's rotund midsection.\n",
      "The visage of Santa Claus's ample abdomen was conjured within her thoughts when she beheld the yeast-infused dough.\n",
      "0\n",
      "complex\n",
      "Upon his realization that numerous fatalities had occurred on this very road, his apprehension heightened exponentially upon witnessing the precise numerical value associated with the loss of life.\n",
      "Upon his cognitive awareness of the manifold instances of mortality that had transpired along this particular thoroughfare, his trepidation and unease reached an elevated magnitude when he laid his eyes upon the meticulously pinpointed and exacting numerical representation of the lives forfeited.\n",
      "He found out that there were many deaths on this road, but he became more worried when he saw the specific number.\n",
      "He learned that there were a lot of deaths on this road, but he got more worried when he saw the exact number.\n",
      "1\n",
      "simple\n",
      "He found out that many people had died on this road, but he became even more worried when he saw the specific number.\n",
      "He learned that many people had died on this road, but he got even more worried when he saw the exact number.\n",
      "He became aware that there had been numerous fatalities along this road, but his level of apprehension intensified when he observed the precise tally.\n",
      "His comprehension dawned upon him as he grasped the grim reality that numerous lives had been lost on this particular road, yet his level of trepidation reached its zenith when he laid eyes upon the meticulous numerical enumeration.\n",
      "0\n",
      "complex\n",
      "The landscape was engulfed by an overwhelming abundance of trash, much like the way sprinkles adorn and enhance the appearance of a birthday cake.\n",
      "The unforgiving expanse of the landscape was utterly subdued by an unrelenting deluge of discarded waste, echoing the way in which the delicate, vibrant sprinkles meticulously bedeck and enliven the surface of a meticulously crafted birthday cake.\n",
      "The landscape was filled with trash just like sprinkles on a birthday cake.\n",
      "The landscape had a lot of trash, like sprinkles on a birthday cake.\n",
      "1\n",
      "simple\n",
      "The landscape was filled with trash just like sprinkles on a birthday cake.\n",
      "The landscape had a lot of trash, like sprinkles on a birthday cake.\n",
      "The landscape was engulfed in garbage, resembling the way sprinkles decorate a birthday cake.\n",
      "The vast expanse of land was inundated with copious amounts of refuse, mirroring the manner in which a profusion of sprinkles adorns a celebratory birthday cake.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>more</th>\n",
       "      <th>even_more</th>\n",
       "      <th>less</th>\n",
       "      <th>even_less</th>\n",
       "      <th>property</th>\n",
       "      <th>adjective</th>\n",
       "      <th>antonym?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>The previous week, I was involved in a vehicul...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>During the preceding week, I found myself embr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>I had a car accident last week.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>I had a crash with my car last week.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>Last week, I was in a car crash.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>Last week, my car crashed.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>Last week I was involved in a collision while ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>During the course of the previous week, I was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>She had some amazing news to share but nobody ...</td>\n",
       "      <td>She was in possession of astounding news, yet ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>She had some amazing news to share but nobody ...</td>\n",
       "      <td>She found herself in the possession of awe-ins...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>She had some amazing news to share but nobody ...</td>\n",
       "      <td>She had incredible news to tell, but no one to...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>She had some amazing news to share but nobody ...</td>\n",
       "      <td>She had really great news, but no one to tell ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>She had some amazing news to share but nobody ...</td>\n",
       "      <td>She had some great news to tell but no one to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>She had some amazing news to share but nobody ...</td>\n",
       "      <td>She had really good news, but no one to tell i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>She had some amazing news to share but nobody ...</td>\n",
       "      <td>She possessed extraordinary tidings to impart,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>She had some amazing news to share but nobody ...</td>\n",
       "      <td>She harbored astonishing revelations to dissem...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sometime you just have to give up and win by c...</td>\n",
       "      <td>Occasionally, one must relinquish and emerge v...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sometime you just have to give up and win by c...</td>\n",
       "      <td>On certain occasions, it becomes necessary to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sometime you just have to give up and win by c...</td>\n",
       "      <td>Sometimes you have no choice but to resort to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sometime you just have to give up and win by c...</td>\n",
       "      <td>Sometimes, cheating is the only way to win.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sometime you just have to give up and win by c...</td>\n",
       "      <td>Sometimes you just have to cheat to win.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sometime you just have to give up and win by c...</td>\n",
       "      <td>Sometimes you have to cheat to win.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sometime you just have to give up and win by c...</td>\n",
       "      <td>Occasionally, one must relinquish and achieve ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sometime you just have to give up and win by c...</td>\n",
       "      <td>On certain occasions, it becomes necessary to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>They desperately needed another drummer since ...</td>\n",
       "      <td>Due to an urgent requirement, an additional pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>They desperately needed another drummer since ...</td>\n",
       "      <td>In light of their acute predicament, it became...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>They desperately needed another drummer since ...</td>\n",
       "      <td>They really needed a new drummer because the c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>They desperately needed another drummer since ...</td>\n",
       "      <td>They really needed a new drummer because the c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>They desperately needed another drummer since ...</td>\n",
       "      <td>They really needed a new drummer because the c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>They desperately needed another drummer since ...</td>\n",
       "      <td>They really needed a new drummer because the c...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>They desperately needed another drummer since ...</td>\n",
       "      <td>They were in dire need of an additional percus...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>They desperately needed another drummer since ...</td>\n",
       "      <td>They were in dire straits, desperately requiri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The bread dough reminded her of Santa Clause’s...</td>\n",
       "      <td>The dough of the bread invoked in her mind the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The bread dough reminded her of Santa Clause’s...</td>\n",
       "      <td>The visage of Santa Claus's ample abdomen was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The bread dough reminded her of Santa Clause’s...</td>\n",
       "      <td>The dough reminded her of Santa's belly.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>The bread dough reminded her of Santa Clause’s...</td>\n",
       "      <td>The dough reminded her of Santa's tummy.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>The bread dough reminded her of Santa Clause’s...</td>\n",
       "      <td>The dough reminded her of Santa's belly.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>The bread dough reminded her of Santa Clause’s...</td>\n",
       "      <td>The dough reminded her of Santa's tummy.</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The bread dough reminded her of Santa Clause’s...</td>\n",
       "      <td>The dough of the bread invoked in her mind the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>The bread dough reminded her of Santa Clause’s...</td>\n",
       "      <td>The visage of Santa Claus's ample abdomen was ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>He realized there had been several deaths on t...</td>\n",
       "      <td>Upon his realization that numerous fatalities ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>He realized there had been several deaths on t...</td>\n",
       "      <td>Upon his cognitive awareness of the manifold i...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>He realized there had been several deaths on t...</td>\n",
       "      <td>He found out that there were many deaths on th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>He realized there had been several deaths on t...</td>\n",
       "      <td>He learned that there were a lot of deaths on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>He realized there had been several deaths on t...</td>\n",
       "      <td>He found out that many people had died on this...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>He realized there had been several deaths on t...</td>\n",
       "      <td>He learned that many people had died on this r...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>He realized there had been several deaths on t...</td>\n",
       "      <td>He became aware that there had been numerous f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>He realized there had been several deaths on t...</td>\n",
       "      <td>His comprehension dawned upon him as he graspe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Trash covered the landscape like sprinkles do ...</td>\n",
       "      <td>The landscape was engulfed by an overwhelming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Trash covered the landscape like sprinkles do ...</td>\n",
       "      <td>The unforgiving expanse of the landscape was u...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Trash covered the landscape like sprinkles do ...</td>\n",
       "      <td>The landscape was filled with trash just like ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Trash covered the landscape like sprinkles do ...</td>\n",
       "      <td>The landscape had a lot of trash, like sprinkl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Trash covered the landscape like sprinkles do ...</td>\n",
       "      <td>The landscape was filled with trash just like ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Trash covered the landscape like sprinkles do ...</td>\n",
       "      <td>The landscape had a lot of trash, like sprinkl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Trash covered the landscape like sprinkles do ...</td>\n",
       "      <td>The landscape was engulfed in garbage, resembl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Trash covered the landscape like sprinkles do ...</td>\n",
       "      <td>The vast expanse of land was inundated with co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence  \\\n",
       "0                Last week I got into a car accident.   \n",
       "1                Last week I got into a car accident.   \n",
       "2                Last week I got into a car accident.   \n",
       "3                Last week I got into a car accident.   \n",
       "4                Last week I got into a car accident.   \n",
       "5                Last week I got into a car accident.   \n",
       "6                Last week I got into a car accident.   \n",
       "7                Last week I got into a car accident.   \n",
       "8   She had some amazing news to share but nobody ...   \n",
       "9   She had some amazing news to share but nobody ...   \n",
       "10  She had some amazing news to share but nobody ...   \n",
       "11  She had some amazing news to share but nobody ...   \n",
       "12  She had some amazing news to share but nobody ...   \n",
       "13  She had some amazing news to share but nobody ...   \n",
       "14  She had some amazing news to share but nobody ...   \n",
       "15  She had some amazing news to share but nobody ...   \n",
       "16  Sometime you just have to give up and win by c...   \n",
       "17  Sometime you just have to give up and win by c...   \n",
       "18  Sometime you just have to give up and win by c...   \n",
       "19  Sometime you just have to give up and win by c...   \n",
       "20  Sometime you just have to give up and win by c...   \n",
       "21  Sometime you just have to give up and win by c...   \n",
       "22  Sometime you just have to give up and win by c...   \n",
       "23  Sometime you just have to give up and win by c...   \n",
       "24  They desperately needed another drummer since ...   \n",
       "25  They desperately needed another drummer since ...   \n",
       "26  They desperately needed another drummer since ...   \n",
       "27  They desperately needed another drummer since ...   \n",
       "28  They desperately needed another drummer since ...   \n",
       "29  They desperately needed another drummer since ...   \n",
       "30  They desperately needed another drummer since ...   \n",
       "31  They desperately needed another drummer since ...   \n",
       "32  The bread dough reminded her of Santa Clause’s...   \n",
       "33  The bread dough reminded her of Santa Clause’s...   \n",
       "34  The bread dough reminded her of Santa Clause’s...   \n",
       "35  The bread dough reminded her of Santa Clause’s...   \n",
       "36  The bread dough reminded her of Santa Clause’s...   \n",
       "37  The bread dough reminded her of Santa Clause’s...   \n",
       "38  The bread dough reminded her of Santa Clause’s...   \n",
       "39  The bread dough reminded her of Santa Clause’s...   \n",
       "40  He realized there had been several deaths on t...   \n",
       "41  He realized there had been several deaths on t...   \n",
       "42  He realized there had been several deaths on t...   \n",
       "43  He realized there had been several deaths on t...   \n",
       "44  He realized there had been several deaths on t...   \n",
       "45  He realized there had been several deaths on t...   \n",
       "46  He realized there had been several deaths on t...   \n",
       "47  He realized there had been several deaths on t...   \n",
       "48  Trash covered the landscape like sprinkles do ...   \n",
       "49  Trash covered the landscape like sprinkles do ...   \n",
       "50  Trash covered the landscape like sprinkles do ...   \n",
       "51  Trash covered the landscape like sprinkles do ...   \n",
       "52  Trash covered the landscape like sprinkles do ...   \n",
       "53  Trash covered the landscape like sprinkles do ...   \n",
       "54  Trash covered the landscape like sprinkles do ...   \n",
       "55  Trash covered the landscape like sprinkles do ...   \n",
       "\n",
       "                                                 text  more  even_more  less  \\\n",
       "0   The previous week, I was involved in a vehicul...     1          0     0   \n",
       "1   During the preceding week, I found myself embr...     0          1     0   \n",
       "2                     I had a car accident last week.     0          0     1   \n",
       "3                I had a crash with my car last week.     0          0     0   \n",
       "4                    Last week, I was in a car crash.     1          0     0   \n",
       "5                          Last week, my car crashed.     0          1     0   \n",
       "6   Last week I was involved in a collision while ...     0          0     1   \n",
       "7   During the course of the previous week, I was ...     0          0     0   \n",
       "8   She was in possession of astounding news, yet ...     1          0     0   \n",
       "9   She found herself in the possession of awe-ins...     0          1     0   \n",
       "10  She had incredible news to tell, but no one to...     0          0     1   \n",
       "11  She had really great news, but no one to tell ...     0          0     0   \n",
       "12  She had some great news to tell but no one to ...     1          0     0   \n",
       "13  She had really good news, but no one to tell i...     0          1     0   \n",
       "14  She possessed extraordinary tidings to impart,...     0          0     1   \n",
       "15  She harbored astonishing revelations to dissem...     0          0     0   \n",
       "16  Occasionally, one must relinquish and emerge v...     1          0     0   \n",
       "17  On certain occasions, it becomes necessary to ...     0          1     0   \n",
       "18  Sometimes you have no choice but to resort to ...     0          0     1   \n",
       "19        Sometimes, cheating is the only way to win.     0          0     0   \n",
       "20           Sometimes you just have to cheat to win.     1          0     0   \n",
       "21                Sometimes you have to cheat to win.     0          1     0   \n",
       "22  Occasionally, one must relinquish and achieve ...     0          0     1   \n",
       "23  On certain occasions, it becomes necessary to ...     0          0     0   \n",
       "24  Due to an urgent requirement, an additional pe...     1          0     0   \n",
       "25  In light of their acute predicament, it became...     0          1     0   \n",
       "26  They really needed a new drummer because the c...     0          0     1   \n",
       "27  They really needed a new drummer because the c...     0          0     0   \n",
       "28  They really needed a new drummer because the c...     1          0     0   \n",
       "29  They really needed a new drummer because the c...     0          1     0   \n",
       "30  They were in dire need of an additional percus...     0          0     1   \n",
       "31  They were in dire straits, desperately requiri...     0          0     0   \n",
       "32  The dough of the bread invoked in her mind the...     1          0     0   \n",
       "33  The visage of Santa Claus's ample abdomen was ...     0          1     0   \n",
       "34           The dough reminded her of Santa's belly.     0          0     1   \n",
       "35           The dough reminded her of Santa's tummy.     0          0     0   \n",
       "36           The dough reminded her of Santa's belly.     1          0     0   \n",
       "37           The dough reminded her of Santa's tummy.     0          1     0   \n",
       "38  The dough of the bread invoked in her mind the...     0          0     1   \n",
       "39  The visage of Santa Claus's ample abdomen was ...     0          0     0   \n",
       "40  Upon his realization that numerous fatalities ...     1          0     0   \n",
       "41  Upon his cognitive awareness of the manifold i...     0          1     0   \n",
       "42  He found out that there were many deaths on th...     0          0     1   \n",
       "43  He learned that there were a lot of deaths on ...     0          0     0   \n",
       "44  He found out that many people had died on this...     1          0     0   \n",
       "45  He learned that many people had died on this r...     0          1     0   \n",
       "46  He became aware that there had been numerous f...     0          0     1   \n",
       "47  His comprehension dawned upon him as he graspe...     0          0     0   \n",
       "48  The landscape was engulfed by an overwhelming ...     1          0     0   \n",
       "49  The unforgiving expanse of the landscape was u...     0          1     0   \n",
       "50  The landscape was filled with trash just like ...     0          0     1   \n",
       "51  The landscape had a lot of trash, like sprinkl...     0          0     0   \n",
       "52  The landscape was filled with trash just like ...     1          0     0   \n",
       "53  The landscape had a lot of trash, like sprinkl...     0          1     0   \n",
       "54  The landscape was engulfed in garbage, resembl...     0          0     1   \n",
       "55  The vast expanse of land was inundated with co...     0          0     0   \n",
       "\n",
       "    even_less    property adjective  antonym?  \n",
       "0           0  complexity   complex         0  \n",
       "1           0  complexity   complex         0  \n",
       "2           0  complexity   complex         0  \n",
       "3           1  complexity   complex         0  \n",
       "4           0  complexity    simple         1  \n",
       "5           0  complexity    simple         1  \n",
       "6           0  complexity    simple         1  \n",
       "7           1  complexity    simple         1  \n",
       "8           0  complexity   complex         0  \n",
       "9           0  complexity   complex         0  \n",
       "10          0  complexity   complex         0  \n",
       "11          1  complexity   complex         0  \n",
       "12          0  complexity    simple         1  \n",
       "13          0  complexity    simple         1  \n",
       "14          0  complexity    simple         1  \n",
       "15          1  complexity    simple         1  \n",
       "16          0  complexity   complex         0  \n",
       "17          0  complexity   complex         0  \n",
       "18          0  complexity   complex         0  \n",
       "19          1  complexity   complex         0  \n",
       "20          0  complexity    simple         1  \n",
       "21          0  complexity    simple         1  \n",
       "22          0  complexity    simple         1  \n",
       "23          1  complexity    simple         1  \n",
       "24          0  complexity   complex         0  \n",
       "25          0  complexity   complex         0  \n",
       "26          0  complexity   complex         0  \n",
       "27          1  complexity   complex         0  \n",
       "28          0  complexity    simple         1  \n",
       "29          0  complexity    simple         1  \n",
       "30          0  complexity    simple         1  \n",
       "31          1  complexity    simple         1  \n",
       "32          0  complexity   complex         0  \n",
       "33          0  complexity   complex         0  \n",
       "34          0  complexity   complex         0  \n",
       "35          1  complexity   complex         0  \n",
       "36          0  complexity    simple         1  \n",
       "37          0  complexity    simple         1  \n",
       "38          0  complexity    simple         1  \n",
       "39          1  complexity    simple         1  \n",
       "40          0  complexity   complex         0  \n",
       "41          0  complexity   complex         0  \n",
       "42          0  complexity   complex         0  \n",
       "43          1  complexity   complex         0  \n",
       "44          0  complexity    simple         1  \n",
       "45          0  complexity    simple         1  \n",
       "46          0  complexity    simple         1  \n",
       "47          1  complexity    simple         1  \n",
       "48          0  complexity   complex         0  \n",
       "49          0  complexity   complex         0  \n",
       "50          0  complexity   complex         0  \n",
       "51          1  complexity   complex         0  \n",
       "52          0  complexity    simple         1  \n",
       "53          0  complexity    simple         1  \n",
       "54          0  complexity    simple         1  \n",
       "55          1  complexity    simple         1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO save 5 responses instead of 1\n",
    "\n",
    "\n",
    "adj, antonym = property_dict['complexity']\n",
    "\n",
    "data = []\n",
    "\n",
    "for sent in sentences:\n",
    "\n",
    "    for i, x in enumerate([adj, antonym]):\n",
    "        print(i)\n",
    "        print(x)\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a rewording assistant, skilled in transforming a statement to express more or less of a given quality or property.\"},\n",
    "        ]\n",
    "\n",
    "        \n",
    "        # more\n",
    "        more_messages = messages + [{\"role\": \"user\", \"content\": \"Rephrase the following statement to use language that is more {}: \\\"{}\\\" .\".format(x,sent)}]\n",
    "        more = complete(more_messages)\n",
    "        row = {\n",
    "             'sentence': sent,\n",
    "             'text': more,\n",
    "             'more': 1,\n",
    "             'even_more': 0,\n",
    "             'less': 0,\n",
    "             'even_less':  0,\n",
    "             'property': 'complexity',\n",
    "             'adjective': x,\n",
    "             'antonym?': 0 if i == 0 else 1 # the second in the pair is the antonym\n",
    "        }\n",
    "        data.append(row)\n",
    "        print(more)\n",
    "                         \n",
    "        # even more\n",
    "        even_more_messages = more_messages + [{\"role\": \"system\", \"content\": more}] + [{\"role\": \"user\", \"content\": \"Good. Rephrase the sentence again to use language that is even more {}.\".format(x)}]\n",
    "        even_more = complete(even_more_messages)\n",
    "        row = {\n",
    "             'sentence': sent,\n",
    "             'text': even_more,\n",
    "             'more': 0,\n",
    "             'even_more': 1,\n",
    "             'less': 0,\n",
    "             'even_less':  0,\n",
    "             'property': 'complexity',\n",
    "             'adjective': x,\n",
    "             'antonym?': 0 if i == 0 else 1 # the second in the pair is the antonym\n",
    "        }\n",
    "        data.append(row)\n",
    "        print(even_more)\n",
    "\n",
    "        # TODO even even more\n",
    "\n",
    "        # less\n",
    "        less_messages = messages + [{\"role\": \"user\", \"content\": \"Rephrase the following statement to use language that is less {}: \\\"{}\\\" .\".format(x,sent)}]\n",
    "        less = complete(less_messages)\n",
    "        row = {\n",
    "             'sentence': sent,\n",
    "             'text': less,\n",
    "             'more': 0,\n",
    "             'even_more': 0,\n",
    "             'less': 1,\n",
    "             'even_less':  0,\n",
    "             'property': 'complexity',\n",
    "             'adjective': x,\n",
    "             'antonym?': 0 if i == 0 else 1 # the second in the pair is the antonym\n",
    "        }\n",
    "        data.append(row)\n",
    "        print(less)\n",
    "\n",
    "        # even less\n",
    "        even_less_messages = less_messages + [{\"role\": \"system\", \"content\": less}] + [{\"role\": \"user\", \"content\": \"Good. Rephrase the sentence again to use language that is even less {}.\".format(x)}]\n",
    "        even_less = complete(even_less_messages)\n",
    "        row = {\n",
    "             'sentence': sent,\n",
    "             'text': even_less,\n",
    "             'more': 0,\n",
    "             'even_more': 0,\n",
    "             'less': 0,\n",
    "             'even_less':  1,\n",
    "             'property': 'complexity',\n",
    "             'adjective': x,\n",
    "             'antonym?': 0 if i == 0 else 1 # the second in the pair is the antonym\n",
    "        }\n",
    "        data.append(row)\n",
    "        print(even_less)\n",
    "\n",
    "    \n",
    "df = pd.DataFrame.from_records(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b25f89-ab88-465e-ace6-2aec86468b4d",
   "metadata": {},
   "source": [
    "Save so we don't have to query the api every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9085cb6-5312-4702-9341-3361cf5b3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('make_it_more_complexity_pilot_seed_sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b7bb7-525d-431b-8fd5-edfa97a43fa0",
   "metadata": {},
   "source": [
    "## Step 2: Calculating the formality dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f523f9c0-24dd-418d-86a6-ec53d765f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('make_it_more_complexity_pilot_seed_sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fd9466-fe30-49f1-ae00-d4f997d50553",
   "metadata": {},
   "source": [
    "Now that we have our seed sentences for the complexity dimension, we need to get the vector differences for the seed pairs.\n",
    "\n",
    "We generated 8 sentences for each original seed sentence, meaning we have four seed pairs.\n",
    "\n",
    "The formulas for the four seed pairs are as follows:\n",
    "\n",
    "- ( adjective + more ) - (adjective + less)\n",
    "- ( adjective + even more ) - (adjective + even less)\n",
    "- ( antonym + less ) - (antonym + more )\n",
    "- ( antonym + even less ) - (antonym + even more )\n",
    "\n",
    "First we get an embedding for each sentence. Then, for each seed sentence we calculate these four formulae to get the vector differences, storing those in a separate list. And then we average those together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b334804-1706-4470-84b1-822400f96bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>more</th>\n",
       "      <th>even_more</th>\n",
       "      <th>less</th>\n",
       "      <th>even_less</th>\n",
       "      <th>property</th>\n",
       "      <th>adjective</th>\n",
       "      <th>antonym?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>The previous week, I was involved in a vehicul...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>During the preceding week, I found myself embr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>I had a car accident last week.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>I had a crash with my car last week.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>Last week, I was in a car crash.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0                              sentence  \\\n",
       "0             0           0  Last week I got into a car accident.   \n",
       "1             1           1  Last week I got into a car accident.   \n",
       "2             2           2  Last week I got into a car accident.   \n",
       "3             3           3  Last week I got into a car accident.   \n",
       "4             4           4  Last week I got into a car accident.   \n",
       "\n",
       "                                                text  more  even_more  less  \\\n",
       "0  The previous week, I was involved in a vehicul...     1          0     0   \n",
       "1  During the preceding week, I found myself embr...     0          1     0   \n",
       "2                    I had a car accident last week.     0          0     1   \n",
       "3               I had a crash with my car last week.     0          0     0   \n",
       "4                   Last week, I was in a car crash.     1          0     0   \n",
       "\n",
       "   even_less    property adjective  antonym?  \n",
       "0          0  complexity   complex         0  \n",
       "1          0  complexity   complex         0  \n",
       "2          0  complexity   complex         0  \n",
       "3          1  complexity   complex         0  \n",
       "4          0  complexity    simple         1  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd83119a-86ad-4d05-a3ac-c0475cee9a72",
   "metadata": {},
   "source": [
    "--NOPE__So now that we have our seed sentences for the complexity dimension, we need to split them into negative and positive sentences. The generated sentences should be divided as follows.\n",
    "\n",
    "Positive\n",
    "- adjective + more\n",
    "- adjective + even more\n",
    "- antonym + less\n",
    "- antonym + even less\n",
    "\n",
    "Negative\n",
    "- adjective + less\n",
    "- adjective + even less\n",
    "- antonym + more\n",
    "- antonym + even more\n",
    "\n",
    "After we split them into positive and negative examples, we embed them using SBERT--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15e7b58d-deba-48dd-af07-0ab2640bf699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# positive = df[df['antonym?']==0][df['more']==1]['text'].to_list() + df[df['antonym?']==0][df['even_more']==1]['text'].to_list() + df[df['antonym?']==1][df['less']==1]['text'].to_list() + df[df['antonym?']==1][df['even_less']==1]['text'].to_list() \n",
    "# negative = df[df['antonym?']==0][df['less']==1]['text'].to_list() + df[df['antonym?']==0][df['even_less']==1]['text'].to_list() + df[df['antonym?']==1][df['more']==1]['text'].to_list() + df[df['antonym?']==1][df['even_more']==1]['text'].to_list() \n",
    "\n",
    "# print(positive)\n",
    "# print()\n",
    "# print(negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480bb4d3-f829-4a63-b25f-51b65a1a4426",
   "metadata": {},
   "source": [
    "Obviously we run into the problem where vectors are word level and we want sentence-level representations. The absolute simplest thing I can think of to do here is to use SentenceBERT, which we will download from huggingface.\n",
    "\n",
    "After initializing the model, we generate vector representations for each sentence in the informal list and for each corresponding sentence in the formal list. We subtract the vectors from one another and then take the average, leaving us with a vector that represents the formality dimension. We can rate any sentence vector(s) on the formality dimension by giving them (as a list) to the function predict_scalarproj along with the dimension itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1284a-c891-45f3-bd91-6493d068d4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load sbert\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcc3019e-351a-4989-8a8a-499dd380be2e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>sentence</th>\n",
       "      <th>text</th>\n",
       "      <th>more</th>\n",
       "      <th>even_more</th>\n",
       "      <th>less</th>\n",
       "      <th>even_less</th>\n",
       "      <th>property</th>\n",
       "      <th>adjective</th>\n",
       "      <th>antonym?</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>The previous week, I was involved in a vehicul...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.05463976413011551, 0.04207247123122215, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>During the preceding week, I found myself embr...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.016205446794629097, 0.01861356757581234, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>I had a car accident last week.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.01675170101225376, 0.004364470951259136, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>I had a crash with my car last week.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>complexity</td>\n",
       "      <td>complex</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.024704160168766975, 0.015588822774589062, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Last week I got into a car accident.</td>\n",
       "      <td>Last week, I was in a car crash.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>complexity</td>\n",
       "      <td>simple</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.029179640114307404, -0.011056442745029926, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              sentence  \\\n",
       "0           0  Last week I got into a car accident.   \n",
       "1           1  Last week I got into a car accident.   \n",
       "2           2  Last week I got into a car accident.   \n",
       "3           3  Last week I got into a car accident.   \n",
       "4           4  Last week I got into a car accident.   \n",
       "\n",
       "                                                text  more  even_more  less  \\\n",
       "0  The previous week, I was involved in a vehicul...     1          0     0   \n",
       "1  During the preceding week, I found myself embr...     0          1     0   \n",
       "2                    I had a car accident last week.     0          0     1   \n",
       "3               I had a crash with my car last week.     0          0     0   \n",
       "4                   Last week, I was in a car crash.     1          0     0   \n",
       "\n",
       "   even_less    property adjective  antonym?  \\\n",
       "0          0  complexity   complex         0   \n",
       "1          0  complexity   complex         0   \n",
       "2          0  complexity   complex         0   \n",
       "3          1  complexity   complex         0   \n",
       "4          0  complexity    simple         1   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.05463976413011551, 0.04207247123122215, 0.0...  \n",
       "1  [0.016205446794629097, 0.01861356757581234, 0....  \n",
       "2  [-0.01675170101225376, 0.004364470951259136, 0...  \n",
       "3  [0.024704160168766975, 0.015588822774589062, 0...  \n",
       "4  [0.029179640114307404, -0.011056442745029926, ...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "sentences = df['text'].to_list()\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "\n",
    "df = df.assign(embedding=embeddings.tolist())\n",
    "\n",
    "df.head(5)\n",
    "\n",
    "# #Print the embeddings\n",
    "# for sentence, embedding in zip(positive[:5], pos_embeddings[:5]):\n",
    "#     print(\"Sentence:\", sentence)\n",
    "#     print(\"Embedding:\", embedding[:100])\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e3cda30c-3ae2-46ed-8cd4-4f7e4d420929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "difference_vecs = []\n",
    "\n",
    "def more(df):\n",
    "    df = df[df['adjective']=='complex'] \n",
    "    df = df[df['more']==1]\n",
    "    return df\n",
    "\n",
    "def less(df):\n",
    "    df = df[df['adjective']=='complex'] \n",
    "    df = df[df['more']==1]\n",
    "    return df['embedding'].values[0]\n",
    "\n",
    "for sentence in df['sentence'].unique():\n",
    "    # there are 8 seeds with this sentence\n",
    "    print(len(df[df['sentence']==sentence]))\n",
    "    \n",
    "    seeds = df[df['sentence']==sentence]\n",
    "    \n",
    "    # now we want to calculate the four different formulae\n",
    "    \n",
    "    #( adjective + more ) - (adjective + less)\n",
    "    a = seeds[seeds['adjective']=='complex'] \n",
    "    a = seeds[seeds['more']==1] ['embedding'].values[0]\n",
    "    b = seeds[seeds['adjective']=='complex'] \n",
    "    b = seeds[seeds['less']==1] ['embedding'].values[0]\n",
    "    diff_vec = np.asarray(a) - np.asarray(b)\n",
    "    difference_vecs.append(diff_vec)\n",
    "    \n",
    "    #( adjective + even more ) - (adjective + even less)\n",
    "    a = seeds[seeds['adjective']=='complex'] \n",
    "    a = seeds[seeds['even_more']==1] ['embedding'].values[0]\n",
    "    b = seeds[seeds['adjective']=='complex'] \n",
    "    b = seeds[seeds['even_less']==1] ['embedding'].values[0]\n",
    "    diff_vec = np.asarray(a) - np.asarray(b)\n",
    "    difference_vecs.append(diff_vec)\n",
    "    \n",
    "    #( antonym + less ) - (antonym + more )\n",
    "    a = seeds[seeds['adjective']=='simple'] \n",
    "    a = seeds[seeds['less']==1] ['embedding'].values[0]\n",
    "    b = seeds[seeds['adjective']=='simple'] \n",
    "    b = seeds[seeds['more']==1] ['embedding'].values[0]\n",
    "    diff_vec = np.asarray(a) - np.asarray(b)\n",
    "    difference_vecs.append(diff_vec)\n",
    "    \n",
    "    #( antonym + even less ) - (antonym + even more )\n",
    "    a = seeds[seeds['adjective']=='simple'] \n",
    "    a = seeds[seeds['even_less']==1] ['embedding'].values[0]\n",
    "    b = seeds[seeds['adjective']=='simple'] \n",
    "    b = seeds[seeds['even_more']==1] ['embedding'].values[0]\n",
    "    diff_vec = np.asarray(a) - np.asarray(b)\n",
    "    difference_vecs.append(diff_vec)\n",
    "    \n",
    "print(len(difference_vecs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fbb603f9-968c-4a6b-876a-42c3c8a95749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.03994247e-02 -6.06127921e-02  9.14853811e-03 -1.28718689e-02\n",
      "  4.68865782e-03 -3.19791464e-02 -1.44007057e-02  4.25428115e-02\n",
      " -4.08821441e-02  3.97744404e-02 -2.72350453e-02  4.07437040e-02\n",
      "  2.26934589e-02  3.26484535e-02 -6.18782695e-02  4.65744315e-02\n",
      " -4.86825928e-02 -5.79366945e-02 -4.11888286e-02 -7.31274039e-02\n",
      " -2.64015459e-02  1.27541311e-02  7.77818928e-02 -5.24954870e-04\n",
      " -4.39719101e-02  9.29965219e-03  4.17338414e-02  6.45466708e-02\n",
      "  6.60448149e-03 -1.24711413e-02 -1.03509054e-03  3.88942440e-02\n",
      "  5.11108879e-02 -1.08129010e-02 -6.55224267e-02 -1.74900133e-01\n",
      " -5.44179307e-03 -4.79404740e-02 -3.60480137e-03  3.70678650e-02\n",
      "  4.74482216e-03  3.01680929e-03  1.50575889e-02 -6.54721260e-03\n",
      " -2.34416593e-02 -1.27597973e-02  2.91121751e-03 -4.61295992e-02\n",
      "  1.25788107e-01 -3.33999991e-02  1.88923515e-02 -8.66836868e-03\n",
      "  4.77682175e-02 -3.29941884e-02  7.08529465e-02 -1.27413504e-01\n",
      " -5.19959852e-02 -1.33465917e-03 -3.66910920e-03  1.19598340e-01\n",
      "  3.02098254e-02 -4.43065548e-02  2.29169368e-02 -9.72260647e-02\n",
      "  1.64048709e-02  1.42204759e-02 -2.06448697e-02 -3.42158526e-02\n",
      " -3.62482446e-02 -1.43337548e-02 -4.94744722e-03  7.42106959e-02\n",
      " -2.57792696e-03 -9.30004567e-03 -4.29391116e-03 -2.65979357e-02\n",
      "  2.76396312e-02  3.48425852e-02 -7.88647588e-03 -4.67905486e-02\n",
      " -1.19698154e-01 -5.68461530e-02  1.27518931e-02  2.57738354e-02\n",
      "  8.46227575e-02  4.77652997e-03 -2.17871526e-02  4.06281715e-02\n",
      " -1.32937067e-02  1.65959969e-02  3.15570205e-02  8.99102837e-02\n",
      "  3.58475731e-02  7.82290203e-02  1.84282660e-04  9.01344446e-02\n",
      " -6.73551112e-03  3.72114535e-02 -3.95630673e-02 -5.50053939e-02\n",
      " -2.93988371e-02  5.21171093e-03  5.63716739e-02 -4.90259901e-02\n",
      " -4.08846820e-02  1.10795073e-01  6.93797767e-02  4.77961851e-02\n",
      " -2.28427872e-02  5.90357957e-02  7.85147883e-02  1.14908279e-01\n",
      " -2.18510963e-02  6.18242018e-02 -4.22856323e-02 -1.16086215e-01\n",
      "  4.00585681e-02  2.32600048e-03 -3.41175599e-02  7.36484453e-02\n",
      " -2.68821456e-02 -6.75361054e-02 -1.49140959e-02  4.40495964e-02\n",
      "  4.44228565e-02  3.74115277e-02  3.61309201e-03 -6.92875070e-33\n",
      "  8.65457971e-02  4.26646844e-02  6.01009228e-02 -5.76408971e-02\n",
      "  4.26409245e-02 -1.92448562e-02  3.38265598e-02  1.86856079e-02\n",
      " -1.34106055e-02 -6.77959481e-02 -2.06895061e-02 -1.41044091e-01\n",
      " -2.79413797e-02 -7.67746959e-02  2.88574547e-02  9.26679000e-03\n",
      " -1.04502961e-02 -6.53744042e-02 -6.81417827e-02 -2.59680599e-02\n",
      "  4.23903186e-02 -7.60211218e-02 -1.11840630e-03 -2.19465047e-03\n",
      "  6.95423186e-02  9.97975376e-02  4.12695687e-02  3.23560908e-02\n",
      "  1.35115739e-01 -1.93967847e-02 -1.77129880e-02  1.52248889e-02\n",
      "  3.69503582e-02  1.18290488e-01  1.78895809e-02  3.10017746e-02\n",
      "  3.40468436e-03 -1.03712277e-02 -4.34341703e-02 -9.32313874e-03\n",
      " -3.53430957e-03 -5.61392941e-02 -6.32252973e-02  4.36356813e-02\n",
      " -9.42601264e-03 -2.37403922e-02 -4.52990904e-02  2.06724787e-02\n",
      "  2.45466940e-02 -4.73093614e-03 -4.61454038e-02 -1.07573587e-02\n",
      " -4.31345124e-02  3.87631599e-02  5.57757318e-02  3.28403171e-02\n",
      " -2.39404698e-03 -4.67136444e-02 -5.79519067e-02  1.02841511e-01\n",
      " -2.31667832e-02  7.20932819e-02  7.84742646e-02  7.25699496e-02\n",
      " -4.16822610e-02  3.91492611e-02  4.32164539e-02  8.97310320e-02\n",
      "  2.01080851e-02  9.78496671e-03  7.03263544e-02 -2.13868835e-03\n",
      " -3.89886983e-02  3.47925723e-03 -2.02712268e-02 -2.84595974e-02\n",
      " -3.37047968e-02  5.17543941e-02  1.15183495e-01 -5.15907509e-02\n",
      "  3.35621461e-02  5.01881428e-02  3.38130132e-02 -3.73977236e-03\n",
      " -1.68883651e-02  5.02336081e-02 -2.06575100e-03 -9.14819352e-03\n",
      " -3.17483880e-02  1.62525550e-02  5.14877206e-02 -9.71733220e-02\n",
      " -3.48653384e-02  2.78699398e-03 -1.20372176e-02  4.76195452e-33\n",
      " -1.44350095e-01  1.45639209e-02  3.59552207e-02  1.38850510e-03\n",
      " -3.93256731e-02 -5.92448078e-02  7.54717737e-02  9.69860354e-04\n",
      "  1.27288815e-01  2.37799380e-02  6.06479160e-02  3.82542834e-02\n",
      " -7.90333599e-02 -6.99019060e-03  6.35372452e-02 -6.46123057e-02\n",
      "  1.36725963e-02 -2.96137510e-02  3.01251058e-02  1.93125913e-02\n",
      " -4.65305962e-02  1.50428079e-02  3.78999673e-02  1.26508564e-01\n",
      " -5.17053262e-02 -6.10788204e-02 -9.42483209e-02 -3.86261912e-02\n",
      "  2.91955993e-02  2.33037919e-02 -4.07310156e-03  1.52543299e-02\n",
      "  4.32075299e-02  3.01494263e-02 -3.86680011e-02 -4.39489186e-02\n",
      " -3.28407884e-02 -3.21788117e-02  1.36543401e-02  5.97658968e-02\n",
      "  6.47145647e-02 -3.21449508e-02  2.29012184e-02 -2.16251891e-02\n",
      " -6.60405643e-02  7.81628676e-02  5.28912563e-02  4.31798846e-02\n",
      " -5.32783382e-02 -5.20805236e-02  7.13802064e-02 -1.54606141e-02\n",
      " -8.45972523e-02  4.38922718e-02  2.51578083e-02  5.56942001e-02\n",
      "  7.96706043e-02  7.86966942e-02 -1.77783668e-02  5.66772115e-02\n",
      " -5.23727955e-02  4.92269620e-02 -3.93321440e-02  1.15845203e-02\n",
      " -6.23809304e-02 -8.14707987e-02 -8.11432116e-02 -9.86748971e-02\n",
      "  7.30912285e-02 -1.25114378e-02  8.40321667e-02  4.11438383e-02\n",
      "  2.23773792e-02  7.86456726e-02 -8.59302655e-02 -4.34366600e-02\n",
      " -5.70332892e-02  2.58463100e-02 -5.15241033e-02  3.61077837e-04\n",
      "  2.01101373e-02 -5.13593853e-02 -1.42628299e-02  5.56374798e-02\n",
      " -4.72029187e-02 -1.21388100e-02  1.07191848e-01 -8.92136618e-03\n",
      " -1.54440608e-02  5.19332411e-02  2.10116990e-03  3.44266854e-02\n",
      "  4.38961014e-02 -2.88258307e-02 -9.22524240e-02  8.93371777e-09\n",
      "  2.43428722e-03  2.41154842e-02  2.53447480e-02 -7.63501655e-02\n",
      "  4.66451123e-02  2.13388770e-02 -1.68401683e-02  8.17567408e-02\n",
      " -5.21503240e-02  3.21395993e-02  5.15899397e-02  1.69507824e-02\n",
      " -4.08645887e-02 -4.45633009e-02 -4.08316143e-02  5.68744540e-03\n",
      "  7.09184987e-03 -7.06735706e-02  5.94140198e-02  2.06294768e-02\n",
      " -2.05169930e-02 -2.21166611e-02  4.11623027e-02  6.98426105e-02\n",
      "  5.38512180e-02 -5.86396540e-02 -5.45922294e-03  1.10304215e-01\n",
      " -1.47145428e-02 -4.47661569e-02  1.19459445e-02 -1.34220313e-01\n",
      " -2.83395518e-02 -2.21379148e-02 -1.27380714e-02  3.62617448e-02\n",
      "  2.40779445e-02 -7.27410987e-03  9.05450592e-02 -9.34279244e-03\n",
      " -1.20984226e-01 -7.71728698e-02  3.49669577e-02 -3.10295559e-02\n",
      " -2.05295682e-02  4.95482925e-02 -1.43339977e-01 -1.05605885e-01\n",
      "  5.47016039e-04 -1.16384368e-01 -4.56517551e-02 -1.35907494e-01\n",
      " -5.28534923e-02 -4.98096613e-02  5.62485978e-02 -5.14957309e-03\n",
      " -1.40777258e-02 -6.62422739e-02  6.46642670e-02 -2.13493779e-02\n",
      " -9.33020655e-02  1.24876238e-02 -4.03209268e-02  1.17215818e-01]\n"
     ]
    }
   ],
   "source": [
    "print(difference_vecs[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3bb8cd79-ef62-492b-aba3-08037f798ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimvec = np.mean(difference_vecs[:8], axis = 0)\n",
    "dimvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421118ae-352e-401e-81d7-b760b10d5e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e55df1-af38-48be-9fc5-104a9d5e429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### from marianna + katrin\n",
    "# seed-based method\n",
    "# averaging over seed pair vectors\n",
    "# def dimension_seedbased(seeds_pos, seeds_neg, space, paired = False):\n",
    "#     diffvectors = [ ]\n",
    "    \n",
    "#     for negword, posword in _make_seedpairs(seeds_pos, seeds_neg, paired = paired):\n",
    "#         diffvectors.append(space[posword] - space[negword])\n",
    "\n",
    "#     # average\n",
    "#     dimvec = np.mean(diffvectors, axis = 0)\n",
    "#     return dimvec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "676f37e8-3dfb-4506-a854-40d052d98229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dimension_seedbased():\n",
    "    return dimvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eee09be1-c023-4eb8-b9e0-3c69b1953c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complexity_dimension = dimension_seedbased()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b5fe2f2b-b07e-4e07-8d93-9692f0f230c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector scalar projection (from marianna + katrin)\n",
    "def predict_scalarproj(veclist, dimension):\n",
    "    dir_veclen = math.sqrt(np.dot(dimension, dimension))\n",
    "    return [np.dot(v, dimension) / dir_veclen for v in veclist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770a039-0b13-4949-a03c-4e3b7a94baf8",
   "metadata": {},
   "source": [
    "# Step 3: validating the formality dimension\n",
    "\n",
    "does it behave the same way as a standard classifier?\n",
    "\n",
    "\n",
    "We load a regular classifier\n",
    "\n",
    "We run this prediction method and the formality classifier on the formality dataset. \n",
    "\n",
    "We compare. Is the dimension-based method that much worse?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c969e44-b386-4cbe-b0ff-e1d6579bbed2",
   "metadata": {},
   "source": [
    "We load a formality dataset - perhaps the word-based one that Marianna uses.\n",
    "\n",
    "We order the entries by their complexity rating and look at where they fall on our complexity axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c895faf-64c3-4e77-aff5-5cbcbb723401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "241aa0ac-ff61-4e2e-9a1c-91a389a5d2fd",
   "metadata": {},
   "source": [
    "## Step 4: Rating Toxicity Datasets for formality\n",
    "\n",
    "We'll start with the 1000-length parallel dataset from the text detoxification paper. \n",
    "\n",
    "We load it in\n",
    "\n",
    "We SBERTize the sentences\n",
    "\n",
    "We pass them to the prediction method. \n",
    "\n",
    "We observe: do toxic and nontoxic comments differ wrt formality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b7294-4f8e-4858-8e99-5dc538488c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0ada82a2-b086-49e5-9311-90da32f03a21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████████████████████████████████████████████████████| 7.73k/7.73k [00:00<00:00, 30.3MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████| 194M/194M [00:15<00:00, 12.8MB/s]\n",
      "Downloading data: 100%|██████████████████████████████████████████████████████████████| 187M/187M [00:15<00:00, 12.4MB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████| 21.0M/21.0M [00:02<00:00, 10.4MB/s]\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████████| 20.8M/20.8M [00:02<00:00, 9.10MB/s]\n",
      "Generating train split: 100%|█████████████████████████████████████| 1804874/1804874 [00:01<00:00, 1175672.09 examples/s]\n",
      "Generating validation split: 100%|█████████████████████████████████████| 97320/97320 [00:00<00:00, 991451.89 examples/s]\n",
      "Generating test split: 100%|██████████████████████████████████████████| 97320/97320 [00:00<00:00, 1106339.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"civil_comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "88eedfbc-f87a-4e90-b549-49127e70d87c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\",\n",
       " 'toxicity': 0.0,\n",
       " 'severe_toxicity': 0.0,\n",
       " 'obscene': 0.0,\n",
       " 'threat': 0.0,\n",
       " 'insult': 0.0,\n",
       " 'identity_attack': 0.0,\n",
       " 'sexual_explicit': 0.0}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c038481e-90a6-4c3d-ace4-905d33419a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\",\n",
       " \"Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!\",\n",
       " 'This is such an urgent design problem; kudos to you for taking it on. Very impressive!',\n",
       " \"Is this something I'll be able to install on my site? When will you be releasing it?\",\n",
       " 'haha you guys are a bunch of losers.',\n",
       " 'ur a sh*tty comment.',\n",
       " 'hahahahahahahahhha suck it.',\n",
       " 'FFFFUUUUUUUUUUUUUUU',\n",
       " 'The ranchers seem motivated by mostly by greed; no one should have the right to allow their animals destroy public land.',\n",
       " \"It was a great show. Not a combo I'd of expected to be good together but it was.\"]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][:10]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31522630-0c67-475c-9f8f-bd8c30f78480",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#########\n",
    "# predicting ratings on a dimension\n",
    "\n",
    "# ...\n",
    "# when we only have the dimension:\n",
    "# vector scalar projection\n",
    "def predict_scalarproj(veclist, dimension):\n",
    "    dir_veclen = math.sqrt(np.dot(dimension, dimension))\n",
    "    return [np.dot(v, dimension) / dir_veclen for v in veclist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888023fb-6553-4648-9442-0083b6325eea",
   "metadata": {},
   "source": [
    "SBERtize the Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d745b7ef-4622-491d-9dec-103ec7691319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence_embs = [model.encode(row) for row in dataset[\"train\"][:100]['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99e1a9-9398-430b-b570-163800aa3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate complexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "62bef2a5-82ac-4379-bc99-32f8af58d633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexity_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "18ddbd7d-45f4-447d-8930-52bbd5f337da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2276147/382801673.py:10: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return [np.dot(v, dimension) / dir_veclen for v in veclist]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, nan, nan, nan, nan]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complexities = predict_scalarproj(sentence_embs, dimvec)\n",
    "\n",
    "# for i, emb in enumerate(sentence_embs):\n",
    "#     dataset[\"train\"][i]['complexity_computed'] = sentence_embs[i]\n",
    "#     complexities.append( sentence_embs[i] )\n",
    "\n",
    "#dataset[\"train\"][:5]\n",
    "complexities[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e6f45-ea73-4c7f-bc55-36ca5b3dfa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][:10]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a258f-5c0b-4166-a6ee-633a6a684ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "scipy.stats.pearsonr(complexities, scores)    # Pearson's r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c1c99-2747-481f-94b1-7e07a93631a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06aa3fe-7a4e-4a68-b58f-c3f7db9e9307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxic_logic",
   "language": "python",
   "name": "toxic_logic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
