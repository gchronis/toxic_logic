{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a58cb-5b9f-4fdc-b81d-21e59551fd35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39528cd5-1643-49f9-9702-52792f327947",
   "metadata": {},
   "source": [
    "# Are informal comments more toxic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bc5adb-a751-44f7-9fb4-6e45bb3b1adf",
   "metadata": {},
   "source": [
    "In this notebook we'll use Marianna Apidianaki's method of calculating interpretable dimensions in semantic vector space on the fly using seed pairs. To start, we want to look at the same dimensions: formality and complexity. But we want to look at the sentence level rather than the word level. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64cd02d-247b-4ed7-aece-9016a3ee1ddc",
   "metadata": {},
   "source": [
    "## Step 1: Generating formality seed pairs\n",
    "\n",
    "We want sevenish pairs of sentences, or really two symmetrical groups of sentences, that can be used to calculate a dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b79f94-e41f-41e9-b776-0b10207066b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = \"\"\"Last week I got into a car accident.\n",
    "She had some amazing news to share but nobody to share it with.\n",
    "Sometime you just have to give up and win by cheating.\n",
    "They desperately needed another drummer since the current one only knew how to play bongos.\n",
    "The bread dough reminded her of Santa Clauseâ€™s belly.\n",
    "He realized there had been several deaths on this road, but his concern rose when he saw the exact number.\n",
    "Trash covered the landscape like sprinkles do a birthday cake.\"\"\"\n",
    "sentences = sentences.split(\"\\n\")\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe446b1-ef07-4030-9eeb-63a0ef9a4c41",
   "metadata": {},
   "source": [
    "### Step 1: Load and use GPT to generate sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a3886f-9fd0-4781-9a94-82542ac05227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI() # OPENAI_API_KEY environment variable must be set. see quickstart tutorial here: https://platform.openai.com/docs/quickstart?context=python\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39baeeff-092f-4b8f-8fde-a95169a56564",
   "metadata": {},
   "source": [
    "Try an example completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bef31c-7484-4c27-bdf0-bcf42db8c648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence = sentences[0]\n",
    "\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a rewording assistant, skilled in transforming a statement to express more or less of a given quality or property.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Rephrase the following statement to use language that is more complex: \\\"{}\\\" .\".format(sentence)}\n",
    "  ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6173d14c-9834-4e43-a916-b5baedbd7fce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d93ffd8-86c4-4953-a94c-7d9d5892a373",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "completion.choices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d343e5f5-a508-4b9a-95c9-ad1315e46fae",
   "metadata": {},
   "source": [
    "We'll feed this output back to the api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d63610d-75c2-4125-aeab-f25cb52ef603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "messages.append({'role': 'system', 'content': completion.choices[0].message.content})\n",
    "messages.append({\"role\": \"user\", \"content\": \"Good. Rephrase the sentence again to use language that is even more complex.\"})\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b443cea8-8f6d-4157-960a-fe70bdf18788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def complete(messages):\n",
    "    completion = client.chat.completions.create(\n",
    "      model=\"gpt-3.5-turbo\",\n",
    "      messages=messages,\n",
    "      seed=42\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "complete(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67e271c-6d51-4466-af8e-cad5e1d08146",
   "metadata": {},
   "source": [
    "### prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443760eb-6c3e-4f17-a195-f79d0c18f0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dictionary of the adjectives we use (property adjective and antonym) to create prompts\n",
    "\n",
    "property_dict = {\n",
    "    'complexity':   ('complex', 'simple'),\n",
    "    'emotion':      ('emotional', 'emotionless')\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a278d-99de-4e3d-a33a-3ce3df86e8ff",
   "metadata": {},
   "source": [
    "We will generate sentences from a series of templates. For each sentence, we want to generate 'more x', 'even more x', as well as 'less x' and 'even less x'. Because the model often produces longer sentences for 'more' prompts, we also prompt for rephrasings using an antonymous adjective. So, for example, we ask for rephrasings that are \"more complex\" as well as rephrasings that are \"less simple\". We then use all of these rephrasings to calculate the complexity dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf12b685-beec-476c-b2e6-b51a4d1ef21f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO save 5 responses instead of 1\n",
    "\n",
    "\n",
    "adj, antonym = property_dict['complexity']\n",
    "\n",
    "data = []\n",
    "\n",
    "for sent in sentences:\n",
    "\n",
    "    for i, x in enumerate([adj, antonym]):\n",
    "        print(i)\n",
    "        print(x)\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a rewording assistant, skilled in transforming a statement to express more or less of a given quality or property.\"},\n",
    "        ]\n",
    "\n",
    "        \n",
    "        # more\n",
    "        more_messages = messages + [{\"role\": \"user\", \"content\": \"Rephrase the following statement to use language that is more {}: \\\"{}\\\" .\".format(x,sent)}]\n",
    "        more = complete(more_messages)\n",
    "        print(more)\n",
    "        \n",
    "        # less\n",
    "        less_messages = messages + [{\"role\": \"user\", \"content\": \"Rephrase the following statement to use language that is less {}: \\\"{}\\\" .\".format(x,sent)}]\n",
    "        less = complete(less_messages)\n",
    "        print(less)\n",
    "        \n",
    "        row = {\n",
    "             'sentence': sent,\n",
    "             'text1': more,\n",
    "             'text2': less,\n",
    "             'more': 1,\n",
    "             'even_more': 0,\n",
    "             'less': 1,\n",
    "             'even_less':  0,\n",
    "             'property': 'complexity',\n",
    "             'adjective': x,\n",
    "             'antonym?': 0 if i == 0 else 1 # the second in the pair is the antonym\n",
    "        }\n",
    "        data.append(row)\n",
    "                \n",
    "        # even more\n",
    "        even_more_messages = more_messages + [{\"role\": \"system\", \"content\": more}] + [{\"role\": \"user\", \"content\": \"Good. Rephrase the sentence again to use language that is even more {}.\".format(x)}]\n",
    "        even_more = complete(even_more_messages)\n",
    "        print(even_more)\n",
    "        \n",
    "        # even less\n",
    "        even_less_messages = less_messages + [{\"role\": \"system\", \"content\": less}] + [{\"role\": \"user\", \"content\": \"Good. Rephrase the sentence again to use language that is even less {}.\".format(x)}]\n",
    "        even_less = complete(even_less_messages)\n",
    "        print(even_less)\n",
    "        \n",
    "        row = {\n",
    "             'sentence': sent,\n",
    "             'text1': even_more,\n",
    "             'text2': even_less,\n",
    "             'more': 0,\n",
    "             'even_more': 1,\n",
    "             'less': 0,\n",
    "             'even_less':  1,\n",
    "             'property': 'complexity',\n",
    "             'adjective': x,\n",
    "             'antonym?': 0 if i == 0 else 1 # the second in the pair is the antonym\n",
    "        }\n",
    "        data.append(row)\n",
    "\n",
    "        # TODO even even more\n",
    "\n",
    "\n",
    "    \n",
    "df = pd.DataFrame.from_records(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b25f89-ab88-465e-ace6-2aec86468b4d",
   "metadata": {},
   "source": [
    "Save so we don't have to query the api every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9085cb6-5312-4702-9341-3361cf5b3e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('make_it_more_complexity_pilot_seed_sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b7bb7-525d-431b-8fd5-edfa97a43fa0",
   "metadata": {},
   "source": [
    "## Step 2: Calculating the formality dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523f9c0-24dd-418d-86a6-ec53d765f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('make_it_more_complexity_pilot_seed_sentences.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fd9466-fe30-49f1-ae00-d4f997d50553",
   "metadata": {},
   "source": [
    "Now that we have our seed sentences for the complexity dimension, we need to get the vector differences for the seed pairs.\n",
    "\n",
    "We generated 8 sentences for each original seed sentence, meaning we have four seed pairs.\n",
    "\n",
    "The formulas for the four seed pairs are as follows:\n",
    "\n",
    "- ( adjective + more ) - (adjective + less)\n",
    "- ( adjective + even more ) - (adjective + even less)\n",
    "- ( antonym + less ) - (antonym + more )\n",
    "- ( antonym + even less ) - (antonym + even more )\n",
    "\n",
    "First we get an embedding for each sentence. Then, for each seed sentence we calculate these four formulae to get the vector differences, storing those in a separate list. And then we average those together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b334804-1706-4470-84b1-822400f96bc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd83119a-86ad-4d05-a3ac-c0475cee9a72",
   "metadata": {},
   "source": [
    "--NOPE__So now that we have our seed sentences for the complexity dimension, we need to split them into negative and positive sentences. The generated sentences should be divided as follows.\n",
    "\n",
    "Positive\n",
    "- adjective + more\n",
    "- adjective + even more\n",
    "- antonym + less\n",
    "- antonym + even less\n",
    "\n",
    "Negative\n",
    "- adjective + less\n",
    "- adjective + even less\n",
    "- antonym + more\n",
    "- antonym + even more\n",
    "\n",
    "After we split them into positive and negative examples, we embed them using SBERT--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e7b58d-deba-48dd-af07-0ab2640bf699",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# positive = df[df['antonym?']==0][df['more']==1]['text'].to_list() + df[df['antonym?']==0][df['even_more']==1]['text'].to_list() + df[df['antonym?']==1][df['less']==1]['text'].to_list() + df[df['antonym?']==1][df['even_less']==1]['text'].to_list() \n",
    "# negative = df[df['antonym?']==0][df['less']==1]['text'].to_list() + df[df['antonym?']==0][df['even_less']==1]['text'].to_list() + df[df['antonym?']==1][df['more']==1]['text'].to_list() + df[df['antonym?']==1][df['even_more']==1]['text'].to_list() \n",
    "\n",
    "# print(positive)\n",
    "# print()\n",
    "# print(negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480bb4d3-f829-4a63-b25f-51b65a1a4426",
   "metadata": {},
   "source": [
    "Obviously we run into the problem where vectors are word level and we want sentence-level representations. The absolute simplest thing I can think of to do here is to use SentenceBERT, which we will download from huggingface.\n",
    "\n",
    "After initializing the model, we generate vector representations for each sentence in the informal list and for each corresponding sentence in the formal list. We subtract the vectors from one another and then take the average, leaving us with a vector that represents the formality dimension. We can rate any sentence vector(s) on the formality dimension by giving them (as a list) to the function predict_scalarproj along with the dimension itself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc1284a-c891-45f3-bd91-6493d068d4b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load sbert\n",
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc3019e-351a-4989-8a8a-499dd380be2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "sentences = df['text'].to_list()\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "\n",
    "df = df.assign(embedding=embeddings.tolist())\n",
    "\n",
    "df.head(5)\n",
    "\n",
    "# #Print the embeddings\n",
    "# for sentence, embedding in zip(positive[:5], pos_embeddings[:5]):\n",
    "#     print(\"Sentence:\", sentence)\n",
    "#     print(\"Embedding:\", embedding[:100])\n",
    "#     print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cda30c-3ae2-46ed-8cd4-4f7e4d420929",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_vecs = []\n",
    "\n",
    "def more(df):\n",
    "    df = df[df['adjective']=='complex'] \n",
    "    df = df[df['more']==1]\n",
    "    return df\n",
    "\n",
    "def less(df):\n",
    "    df = df[df['adjective']=='complex'] \n",
    "    df = df[df['more']==1]\n",
    "    return df['embedding'].values[0]\n",
    "\n",
    "for sentence in df['sentence'].unique():\n",
    "    # there are 8 seeds with this sentence\n",
    "    print(len(df[df['sentence']==sentence]))\n",
    "    \n",
    "    seeds = df[df['sentence']==sentence]\n",
    "    \n",
    "    # now we want to calculate the four different formulae\n",
    "    \n",
    "    #( adjective + more ) - (adjective + less)\n",
    "    a = seeds[seeds['adjective']=='complex'] \n",
    "    a = seeds[seeds['more']==1] ['embedding'].values[0]\n",
    "    b = seeds[seeds['adjective']=='complex'] \n",
    "    b = seeds[seeds['less']==1] ['embedding'].values[0]\n",
    "    diff_vec = np.asarray(a) - np.asarray(b)\n",
    "    difference_vecs.append(diff_vec)\n",
    "    \n",
    "    #( adjective + even more ) - (adjective + even less)\n",
    "    a = seeds[seeds['adjective']=='complex'] \n",
    "    a = seeds[seeds['even_more']==1] ['embedding'].values[0]\n",
    "    b = seeds[seeds['adjective']=='complex'] \n",
    "    b = seeds[seeds['even_less']==1] ['embedding'].values[0]\n",
    "    diff_vec = np.asarray(a) - np.asarray(b)\n",
    "    difference_vecs.append(diff_vec)\n",
    "    \n",
    "    #( antonym + less ) - (antonym + more )\n",
    "    a = seeds[seeds['adjective']=='simple'] \n",
    "    a = seeds[seeds['less']==1] ['embedding'].values[0]\n",
    "    b = seeds[seeds['adjective']=='simple'] \n",
    "    b = seeds[seeds['more']==1] ['embedding'].values[0]\n",
    "    diff_vec = np.asarray(a) - np.asarray(b)\n",
    "    difference_vecs.append(diff_vec)\n",
    "    \n",
    "    #( antonym + even less ) - (antonym + even more )\n",
    "    a = seeds[seeds['adjective']=='simple'] \n",
    "    a = seeds[seeds['even_less']==1] ['embedding'].values[0]\n",
    "    b = seeds[seeds['adjective']=='simple'] \n",
    "    b = seeds[seeds['even_more']==1] ['embedding'].values[0]\n",
    "    diff_vec = np.asarray(a) - np.asarray(b)\n",
    "    difference_vecs.append(diff_vec)\n",
    "    \n",
    "print(len(difference_vecs))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb603f9-968c-4a6b-876a-42c3c8a95749",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(difference_vecs[23])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb8cd79-ef62-492b-aba3-08037f798ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimvec = np.mean(difference_vecs[:8], axis = 0)\n",
    "dimvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421118ae-352e-401e-81d7-b760b10d5e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e55df1-af38-48be-9fc5-104a9d5e429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### from marianna + katrin\n",
    "# seed-based method\n",
    "# averaging over seed pair vectors\n",
    "# def dimension_seedbased(seeds_pos, seeds_neg, space, paired = False):\n",
    "#     diffvectors = [ ]\n",
    "    \n",
    "#     for negword, posword in _make_seedpairs(seeds_pos, seeds_neg, paired = paired):\n",
    "#         diffvectors.append(space[posword] - space[negword])\n",
    "\n",
    "#     # average\n",
    "#     dimvec = np.mean(diffvectors, axis = 0)\n",
    "#     return dimvec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676f37e8-3dfb-4506-a854-40d052d98229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dimension_seedbased():\n",
    "    return dimvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee09be1-c023-4eb8-b9e0-3c69b1953c8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "complexity_dimension = dimension_seedbased()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe2f2b-b07e-4e07-8d93-9692f0f230c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector scalar projection (from marianna + katrin)\n",
    "def predict_scalarproj(veclist, dimension):\n",
    "    dir_veclen = math.sqrt(np.dot(dimension, dimension))\n",
    "    return [np.dot(v, dimension) / dir_veclen for v in veclist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9770a039-0b13-4949-a03c-4e3b7a94baf8",
   "metadata": {},
   "source": [
    "# Step 3: validating the formality dimension\n",
    "\n",
    "does it behave the same way as a standard classifier?\n",
    "\n",
    "\n",
    "We load a regular classifier\n",
    "\n",
    "We run this prediction method and the formality classifier on the formality dataset. \n",
    "\n",
    "We compare. Is the dimension-based method that much worse?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c969e44-b386-4cbe-b0ff-e1d6579bbed2",
   "metadata": {},
   "source": [
    "We load a formality dataset - perhaps the word-based one that Marianna uses.\n",
    "\n",
    "We order the entries by their complexity rating and look at where they fall on our complexity axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c895faf-64c3-4e77-aff5-5cbcbb723401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "241aa0ac-ff61-4e2e-9a1c-91a389a5d2fd",
   "metadata": {},
   "source": [
    "## Step 4: Rating Toxicity Datasets for formality\n",
    "\n",
    "We'll start with the 1000-length parallel dataset from the text detoxification paper. \n",
    "\n",
    "We load it in\n",
    "\n",
    "We SBERTize the sentences\n",
    "\n",
    "We pass them to the prediction method. \n",
    "\n",
    "We observe: do toxic and nontoxic comments differ wrt formality?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671b7294-4f8e-4858-8e99-5dc538488c74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ada82a2-b086-49e5-9311-90da32f03a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"civil_comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eedfbc-f87a-4e90-b549-49127e70d87c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c038481e-90a6-4c3d-ace4-905d33419a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][:10]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31522630-0c67-475c-9f8f-bd8c30f78480",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "#########\n",
    "# predicting ratings on a dimension\n",
    "\n",
    "# ...\n",
    "# when we only have the dimension:\n",
    "# vector scalar projection\n",
    "def predict_scalarproj(veclist, dimension):\n",
    "    dir_veclen = math.sqrt(np.dot(dimension, dimension))\n",
    "    return [np.dot(v, dimension) / dir_veclen for v in veclist]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888023fb-6553-4648-9442-0083b6325eea",
   "metadata": {},
   "source": [
    "SBERtize the Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d745b7ef-4622-491d-9dec-103ec7691319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentence_embs = [model.encode(row) for row in dataset[\"train\"][:100]['text']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed99e1a9-9398-430b-b570-163800aa3204",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate complexity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bef2a5-82ac-4379-bc99-32f8af58d633",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ddbd7d-45f4-447d-8930-52bbd5f337da",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexities = predict_scalarproj(sentence_embs, dimvec)\n",
    "\n",
    "# for i, emb in enumerate(sentence_embs):\n",
    "#     dataset[\"train\"][i]['complexity_computed'] = sentence_embs[i]\n",
    "#     complexities.append( sentence_embs[i] )\n",
    "\n",
    "#dataset[\"train\"][:5]\n",
    "complexities[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e6f45-ea73-4c7f-bc55-36ca5b3dfa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][:10]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963a258f-5c0b-4166-a6ee-633a6a684ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "scipy.stats.pearsonr(complexities, scores)    # Pearson's r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6c1c99-2747-481f-94b1-7e07a93631a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "complexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06aa3fe-7a4e-4a68-b58f-c3f7db9e9307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxic_logic",
   "language": "python",
   "name": "toxic_logic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
